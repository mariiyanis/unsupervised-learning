{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDka-zxZQXO-"
      },
      "source": [
        "# 04 - DBSCAN\n",
        "\n",
        "## Introdução\n",
        "\n",
        "O **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) é um algoritmo de clustering baseado em densidade desenvolvido por Martin Ester e colaboradores em 1996. Diferentemente do K-Means e clustering hierárquico, o DBSCAN não requer que especifiquemos o número de clusters antecipadamente e é capaz de identificar clusters de formas arbitrárias e detectar outliers (ruído).\n",
        "\n",
        "### Características Principais do DBSCAN:\n",
        "\n",
        "1. **Baseado em densidade**: Agrupa pontos que estão densamente empacotados\n",
        "2. **Detecção de ruído**: Identifica automaticamente outliers\n",
        "3. **Forma arbitrária**: Pode encontrar clusters de qualquer formato\n",
        "4. **Número automático de clusters**: Não precisa especificar k antecipadamente\n",
        "5. **Robusto a outliers**: Outliers não afetam a formação dos clusters\n",
        "\n",
        "## Fundamentos Matemáticos\n",
        "\n",
        "O DBSCAN utiliza dois parâmetros principais:\n",
        "- $\\varepsilon$ (eps): raio da vizinhança\n",
        "- $\\text{minPts}$: número mínimo de pontos para formar um cluster\n",
        "\n",
        "### Definições Fundamentais:\n",
        "\n",
        "**1. Vizinhança-$\\varepsilon$**: Para um ponto $p$, sua vizinhança-$\\varepsilon$ é definida como:\n",
        "$$N_\\varepsilon(p) = \\{q \\in D | \\text{dist}(p,q) \\leq \\varepsilon\\}$$\n",
        "\n",
        "**2. Ponto Central (Core Point)**: Um ponto $p$ é um ponto central se:\n",
        "$$|N_\\varepsilon(p)| \\geq \\text{minPts}$$\n",
        "\n",
        "**3. Diretamente Alcançável por Densidade**: Um ponto $q$ é diretamente alcançável por densidade a partir de $p$ se:\n",
        "- $q \\in N_\\varepsilon(p)$ e\n",
        "- $p$ é um ponto central\n",
        "\n",
        "**4. Alcançável por Densidade**: Um ponto $q$ é alcançável por densidade a partir de $p$ se existe uma cadeia de pontos $p_1, p_2, ..., p_n$ onde $p_1 = p$ e $p_n = q$, tal que $p_{i+1}$ é diretamente alcançável por densidade a partir de $p_i$.\n",
        "\n",
        "**5. Conectado por Densidade**: Dois pontos $p$ e $q$ são conectados por densidade se existe um ponto $o$ tal que tanto $p$ quanto $q$ são alcançáveis por densidade a partir de $o$.\n",
        "\n",
        "### Classificação dos Pontos:\n",
        "\n",
        "- **Core Point (Ponto Central)**: $|N_\\varepsilon(p)| \\geq \\text{minPts}$\n",
        "- **Border Point (Ponto de Fronteira)**: $|N_\\varepsilon(p)| < \\text{minPts}$, mas está na vizinhança de um core point\n",
        "- **Noise Point (Ponto de Ruído)**: Não é core nem border point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTZxOQDeQXPC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN as SklearnDBSCAN\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.stats import mode\n",
        "import pandas as pd\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJvrTAxKQXPD"
      },
      "source": [
        "## Implementação do DBSCAN\n",
        "\n",
        "Vamos implementar o algoritmo DBSCAN passo a passo usando apenas NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49wvgHMiQXPD"
      },
      "outputs": [],
      "source": [
        "class DBSCAN:\n",
        "    def __init__(self, eps=0.5, min_pts=5, metric='euclidean'):\n",
        "        \"\"\"Inicializa o DBSCAN com os parâmetros eps e min_pts\"\"\"\n",
        "        self.eps = eps\n",
        "        self.min_pts = min_pts\n",
        "        self.metric = metric\n",
        "        self.labels_ = None\n",
        "        self.core_samples_ = None\n",
        "        self.n_clusters_ = 0\n",
        "\n",
        "    def _calculate_distance_matrix(self, X):\n",
        "        \"\"\"Calcula a matriz de distâncias entre todos os pontos\"\"\"\n",
        "        if self.metric == 'euclidean':\n",
        "            distances = np.linalg.norm(X[:, np.newaxis] - X, axis=2)\n",
        "        # elif self.metric == '...':\n",
        "            # distance = ...\n",
        "        else:\n",
        "            raise ValueError(\"Métrica não suportada\")\n",
        "        return distances\n",
        "\n",
        "    def _get_neighbors(self, point_idx, distance_matrix):\n",
        "        \"\"\"Encontra todos os vizinhos dentro da distância eps\"\"\"\n",
        "        return np.where(distance_matrix[point_idx] <= self.eps)[0]\n",
        "\n",
        "    def _expand_cluster(self, point_idx, neighbors, cluster_id, distance_matrix, visited, labels):\n",
        "        \"\"\"Expande o cluster a partir do ponto inicial\"\"\"\n",
        "        labels[point_idx] = cluster_id\n",
        "        queue = neighbors.tolist()\n",
        "\n",
        "        while queue:\n",
        "            neighbor_idx = queue.pop()\n",
        "\n",
        "            if not visited[neighbor_idx]:\n",
        "                visited[neighbor_idx] = True\n",
        "                neighbor_neighbors = self._get_neighbors(neighbor_idx, distance_matrix)\n",
        "\n",
        "                if len(neighbor_neighbors) >= self.min_pts:\n",
        "                    queue.extend(neighbor_neighbors)\n",
        "\n",
        "            if labels[neighbor_idx] == -1:\n",
        "                labels[neighbor_idx] = cluster_id\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"Executa o algoritmo DBSCAN\"\"\"\n",
        "        n_points = len(X)\n",
        "        visited = np.zeros(n_points, dtype=bool)\n",
        "        cluster_id = 0\n",
        "        self.labels_ = np.full(n_points, -1)  # -1 = ruído\n",
        "        self.core_samples_ = []\n",
        "\n",
        "        distance_matrix = self._calculate_distance_matrix(X)\n",
        "\n",
        "        for point_idx in range(n_points):\n",
        "            if visited[point_idx]:\n",
        "                continue\n",
        "\n",
        "            visited[point_idx] = True\n",
        "            neighbors = self._get_neighbors(point_idx, distance_matrix)\n",
        "\n",
        "            if len(neighbors) >= self.min_pts:   # core point\n",
        "                self.core_samples_.append(point_idx)\n",
        "                self._expand_cluster(point_idx, neighbors, cluster_id, distance_matrix, visited, self.labels_)\n",
        "                cluster_id += 1\n",
        "\n",
        "        self.core_samples_ = np.array(self.core_samples_)\n",
        "        self.n_clusters_ = cluster_id\n",
        "        return self\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        \"\"\"Executa DBSCAN e retorna os labels\"\"\"\n",
        "        self.fit(X)\n",
        "        return self.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmZ8dK9VQXPE"
      },
      "source": [
        "## Demonstração com Dados Sintéticos\n",
        "\n",
        "Vamos criar dados sintéticos para demonstrar o funcionamento do DBSCAN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZBhZ4mGQXPE"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# Cabeça: círculo com leve ruído\n",
        "n_head = 400\n",
        "theta = rng.uniform(0, 2*np.pi, n_head)\n",
        "R = 10 + rng.normal(0, 0.35, n_head)\n",
        "head = np.c_[R*np.cos(theta), R*np.sin(theta)]\n",
        "y_head = np.full(n_head, 0)\n",
        "\n",
        "# Olhos: dois blobs gaussianos\n",
        "n_eye = 100\n",
        "eye_left  = rng.normal(loc=[-3.2,  3.0], scale=[0.45, 0.45], size=(n_eye//2, 2))\n",
        "eye_right = rng.normal(loc=[ 3.2,  3.0], scale=[0.45, 0.45], size=(n_eye - n_eye//2, 2))\n",
        "eyes = np.vstack([eye_left, eye_right])\n",
        "y_eyes = np.full(eyes.shape[0], 1)\n",
        "\n",
        "# Boca: arco inferior com jitter (sorriso)\n",
        "n_mouth = 100\n",
        "phi = rng.uniform(np.deg2rad(200), np.deg2rad(340), n_mouth)  # arco de 200° a 340°\n",
        "Rm = 5 + rng.normal(0, 0.22, n_mouth)\n",
        "mouth = np.c_[Rm*np.cos(phi), -1 + Rm*np.sin(phi)]\n",
        "mouth += rng.normal(0, [0.12, 0.15], mouth.shape)  # engrossar um pouco\n",
        "y_mouth = np.full(n_mouth, 2)\n",
        "\n",
        "# Ruído: pontos aleatórios\n",
        "n_noise = 100\n",
        "noise = rng.uniform(low=[-13, -13], high=[13, 13], size=(n_noise, 2))\n",
        "y_noise = np.full(n_noise, -1)\n",
        "\n",
        "# Concatenar\n",
        "X_synthetic = np.vstack([head, eyes, mouth, noise])\n",
        "true_labels  = np.concatenate([y_head, y_eyes, y_mouth, y_noise])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2-xHKReQXPE"
      },
      "outputs": [],
      "source": [
        "# Visualizar os dados sintéticos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "colors = ['red', 'blue', 'green', 'gray']\n",
        "for i in range(4):\n",
        "    if i == 3:  # ruído\n",
        "        mask = true_labels == -1\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1], c=colors[i], alpha=0.6, s=30, marker='x', label='Ruído')\n",
        "    else:\n",
        "        mask = true_labels == i\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1], c=colors[i], alpha=0.7, s=50, label=f'Cluster {i+1}')\n",
        "\n",
        "plt.title('Dados Sintéticos - Classes Verdadeiras')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_synthetic[:, 0], X_synthetic[:, 1], c='black', alpha=0.6, s=30)\n",
        "plt.title('Dados Sintéticos - Sem Labels')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z86Sy6vPQXPE"
      },
      "outputs": [],
      "source": [
        "dbscan = DBSCAN(eps=1.3, min_pts=7)\n",
        "labels = dbscan.fit_predict(X_synthetic)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "unique_labels = np.unique(labels)\n",
        "colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "for k, label in enumerate(unique_labels):\n",
        "    if label == -1:\n",
        "        # Ruído\n",
        "        mask = labels == label\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1], c='black', marker='x', s=30, alpha=0.6, label='Ruído')\n",
        "    else:\n",
        "        # Clusters\n",
        "        mask = labels == label\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1], c=[colors[k]], s=50, alpha=0.7, label=f'Cluster {label}')\n",
        "\n",
        "# Destacar core points\n",
        "if len(dbscan.core_samples_) > 0:\n",
        "    plt.scatter(X_synthetic[dbscan.core_samples_, 0],\n",
        "                X_synthetic[dbscan.core_samples_, 1],\n",
        "                s=100, facecolors='none', edgecolors='black',\n",
        "                linewidth=2, alpha=0.8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dk6snSCQXPF"
      },
      "source": [
        "## Aplicando DBSCAN aos Dados Sintéticos\n",
        "\n",
        "Agora vamos aplicar nosso algoritmo DBSCAN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNBanGuNQXPF"
      },
      "outputs": [],
      "source": [
        "# Testar diferentes valores de eps e min_pts\n",
        "eps_values = [0.5, 1.3, 2.0]\n",
        "min_pts_values = [3, 5, 8]\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "fig.suptitle('DBSCAN com Diferentes Parâmetros', fontsize=16)\n",
        "\n",
        "for i, eps in enumerate(eps_values):\n",
        "    for j, min_pts in enumerate(min_pts_values):\n",
        "        # Aplicar DBSCAN\n",
        "        dbscan = DBSCAN(eps=eps, min_pts=min_pts)\n",
        "        labels = dbscan.fit_predict(X_synthetic)\n",
        "\n",
        "        # Visualizar resultados\n",
        "        ax = axes[i, j]\n",
        "\n",
        "        unique_labels = np.unique(labels)\n",
        "        colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "        for k, label in enumerate(unique_labels):\n",
        "            if label == -1:\n",
        "                # Ruído\n",
        "                mask = labels == label\n",
        "                ax.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1],\n",
        "                          c='black', marker='x', s=30, alpha=0.6, label='Ruído')\n",
        "            else:\n",
        "                # Clusters\n",
        "                mask = labels == label\n",
        "                ax.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1],\n",
        "                          c=[colors[k]], s=50, alpha=0.7, label=f'Cluster {label}')\n",
        "\n",
        "        # Destacar core points\n",
        "        if len(dbscan.core_samples_) > 0:\n",
        "            ax.scatter(X_synthetic[dbscan.core_samples_, 0],\n",
        "                      X_synthetic[dbscan.core_samples_, 1],\n",
        "                      s=100, facecolors='none', edgecolors='black',\n",
        "                      linewidth=2, alpha=0.8)\n",
        "\n",
        "        ax.set_title(f'eps={eps}, min_pts={min_pts}\\n{dbscan.n_clusters_} clusters')\n",
        "        ax.set_xlabel('Feature 1')\n",
        "        ax.set_ylabel('Feature 2')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FkXP84eQXPG"
      },
      "source": [
        "### Análise com Parâmetros Ótimos\n",
        "\n",
        "Vamos escolher os parâmetros que melhor capturam a estrutura dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKfnVzbpQXPG"
      },
      "outputs": [],
      "source": [
        "# Parâmetros que parecem funcionar melhor\n",
        "best_eps = 1.3\n",
        "best_min_pts = 5\n",
        "\n",
        "# Aplicar DBSCAN com os melhores parâmetros\n",
        "dbscan_best = DBSCAN(eps=best_eps, min_pts=best_min_pts)\n",
        "labels_best = dbscan_best.fit_predict(X_synthetic)\n",
        "\n",
        "# Análise detalhada\n",
        "unique_labels = np.unique(labels_best)\n",
        "n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)\n",
        "n_noise = np.sum(labels_best == -1)\n",
        "n_core_samples = len(dbscan_best.core_samples_)\n",
        "\n",
        "print(f\"Resultados do DBSCAN (eps={best_eps}, min_pts={best_min_pts}):\")\n",
        "print(f\"- Número de clusters encontrados: {n_clusters}\")\n",
        "print(f\"- Número de pontos de ruído: {n_noise}\")\n",
        "print(f\"- Número de core samples: {n_core_samples}\")\n",
        "print(f\"- Labels únicos: {unique_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n7fxPiAQXPG"
      },
      "outputs": [],
      "source": [
        "# Classificar pontos por tipo\n",
        "core_mask = np.zeros(len(X_synthetic), dtype=bool)\n",
        "if len(dbscan_best.core_samples_) > 0:\n",
        "    core_mask[dbscan_best.core_samples_] = True\n",
        "\n",
        "border_mask = (labels_best != -1) & (~core_mask)\n",
        "noise_mask = labels_best == -1\n",
        "\n",
        "print(f\"Classificação dos pontos:\")\n",
        "print(f\"- Core points: {np.sum(core_mask)}\")\n",
        "print(f\"- Border points: {np.sum(border_mask)}\")\n",
        "print(f\"- Noise points: {np.sum(noise_mask)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ24vI-MQXPG"
      },
      "outputs": [],
      "source": [
        "# Visualização detalhada dos tipos de pontos\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Subplot 1: Clusters encontrados\n",
        "plt.subplot(1, 3, 1)\n",
        "colors = plt.cm.Set1(np.linspace(0, 1, max(len(unique_labels), 3)))\n",
        "\n",
        "for i, label in enumerate(unique_labels):\n",
        "    if label == -1:\n",
        "        mask = labels_best == label\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1],\n",
        "                   c='black', marker='x', s=50, alpha=0.8, label='Ruído')\n",
        "    else:\n",
        "        mask = labels_best == label\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1],\n",
        "                   c=[colors[i]], s=60, alpha=0.8, label=f'Cluster {label}')\n",
        "\n",
        "plt.title(f'DBSCAN - Clusters Encontrados\\n{n_clusters} clusters, {n_noise} ruído')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: Tipos de pontos\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X_synthetic[core_mask, 0], X_synthetic[core_mask, 1],\n",
        "           c='red', s=80, alpha=0.8, label='Core Points', marker='o')\n",
        "plt.scatter(X_synthetic[border_mask, 0], X_synthetic[border_mask, 1],\n",
        "           c='blue', s=60, alpha=0.8, label='Border Points', marker='s')\n",
        "plt.scatter(X_synthetic[noise_mask, 0], X_synthetic[noise_mask, 1],\n",
        "           c='black', s=40, alpha=0.8, label='Noise Points', marker='x')\n",
        "\n",
        "plt.title('Classificação dos Pontos')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 3: Comparação com ground truth\n",
        "plt.subplot(1, 3, 3)\n",
        "for i in range(4):\n",
        "    if i == 3:  # ruído\n",
        "        mask = true_labels == -1\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1],\n",
        "                   c='gray', alpha=0.6, s=30, marker='x', label='Ruído Real')\n",
        "    else:\n",
        "        mask = true_labels == i\n",
        "        plt.scatter(X_synthetic[mask, 0], X_synthetic[mask, 1],\n",
        "                   c=colors[i], alpha=0.7, s=50, label=f'Cluster Real {i+1}')\n",
        "\n",
        "plt.title('Ground Truth')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0m8GTgzQXPG"
      },
      "source": [
        "## Estimativa do Parâmetro $\\varepsilon$ usando K-Distance\n",
        "\n",
        "Uma das maiores dificuldades do DBSCAN é escolher o valor apropriado para o parâmetro $\\varepsilon$ (eps). O método **K-Distance** é uma heurística eficaz para estimar este parâmetro.\n",
        "\n",
        "O método K-Distance consiste em:\n",
        "\n",
        "1. **Calcular a k-ésima distância mais próxima** para cada ponto no dataset\n",
        "2. **Ordenar essas distâncias** em ordem decrescente\n",
        "3. **Identificar o \"cotovelo\"** no gráfico resultante\n",
        "\n",
        "A intuição é que pontos dentro de clusters densos terão k-ésimas distâncias pequenas, enquanto pontos de ruído ou em bordas de clusters terão distâncias maiores.\n",
        "\n",
        "### Algoritmo K-Distance:\n",
        "\n",
        "Para um dataset $D$ e parâmetro $k = \\text{minPts} - 1$:\n",
        "\n",
        "1. Para cada ponto $p_i \\in D$:\n",
        "   - Calcule $d_k(p_i)$ = distância ao k-ésimo vizinho mais próximo\n",
        "2. Ordene os valores $d_k(p_i)$\n",
        "3. Plote o gráfico K-Distance\n",
        "4. Escolha $\\varepsilon$ no ponto onde a curva tem maior curvatura (cotovelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQdWV76rQXPG"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def plot_k_distance(X, min_pts, title=\"K-Distance Plot\"):\n",
        "    \"\"\"Plota o gráfico K-Distance usando sklearn.NearestNeighbors.\"\"\"\n",
        "    k = int(min_pts - 1)\n",
        "\n",
        "    nn = NearestNeighbors(n_neighbors=k+1, metric=\"euclidean\")\n",
        "    nn.fit(X)\n",
        "    distances, _ = nn.kneighbors(X)\n",
        "\n",
        "    kth_distances = distances[:, k]\n",
        "    k_distances_sorted = np.sort(kth_distances)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(len(k_distances_sorted)), k_distances_sorted, linewidth=2, label=f'{k}-distance')\n",
        "    plt.xlabel(\"Pontos ordenados por distância\")\n",
        "    plt.ylabel(f\"{k}-distance\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxzYKGdyQXPH"
      },
      "outputs": [],
      "source": [
        "plot_k_distance(X_synthetic, min_pts=5, title=\"K-Distance Plot para Dados Sintéticos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtA3yhRpQXPH"
      },
      "source": [
        "## Vantagens e Desvantagens do DBSCAN\n",
        "\n",
        "### Vantagens:\n",
        "\n",
        "1. **Não requer especificar o número de clusters antecipadamente**\n",
        "2. **Pode encontrar clusters de forma arbitrária** (não apenas esféricos)\n",
        "3. **Identifica automaticamente outliers/ruído**\n",
        "4. **Robusto a outliers** (não afetam a formação dos clusters)\n",
        "5. **Determinístico** (sempre produz os mesmos resultados)\n",
        "\n",
        "### Desvantagens:\n",
        "\n",
        "1. **Sensível aos parâmetros** eps e min_pts\n",
        "2. **Dificuldade com clusters de densidades diferentes**\n",
        "3. **Problemas em alta dimensionalidade** (\"curse of dimensionality\")\n",
        "4. **Complexidade computacional** O(n²) no pior caso\n",
        "5. **Requer escolha cuidadosa da métrica de distância**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIa5_Hj3QXPH"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_epdJAJKQXPH"
      },
      "source": [
        "### Exercício 1: Ajuste de Parâmetros no DBSCAN em 3D\n",
        "\n",
        "Com os dados das **três esferas concêntricas**, realize:\n",
        "\n",
        "1. Plotar o K-Distance para diferentes valores de `min_pts` e sugerir um intervalo adequado para `eps`.\n",
        "2. Selecionar os melhores parâmetros de `min_pts` e `eps`.\n",
        "3. Visualizar em 3D os clusters encontrados (cores diferentes) e comentar a escolha de `eps` e `min_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz3IEPW-QXPH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class DBSCAN:\n",
        "    def __init__(self, eps=0.5, min_pts=5, metric='euclidean'):\n",
        "        self.eps = eps\n",
        "        self.min_pts = min_pts\n",
        "        self.metric = metric\n",
        "        self.labels_ = None\n",
        "        self.core_samples_ = None\n",
        "        self.n_clusters_ = 0\n",
        "\n",
        "    def _calculate_distance_matrix(self, X):\n",
        "        if self.metric == 'euclidean':\n",
        "            distances = np.linalg.norm(X[:, np.newaxis] - X, axis=2)\n",
        "        elif self.metric == 'precomputed':\n",
        "            return X\n",
        "        else:\n",
        "            raise ValueError(\"Métrica não suportada ou não implementada\")\n",
        "        return distances\n",
        "\n",
        "    def _get_neighbors(self, point_idx, distance_matrix):\n",
        "        return np.where(distance_matrix[point_idx] <= self.eps)[0]\n",
        "\n",
        "    def _expand_cluster(self, point_idx, neighbors, cluster_id, distance_matrix, visited, labels):\n",
        "        labels[point_idx] = cluster_id\n",
        "        queue = neighbors.tolist()\n",
        "\n",
        "        while queue:\n",
        "            neighbor_idx = queue.pop()\n",
        "\n",
        "            if not visited[neighbor_idx]:\n",
        "                visited[neighbor_idx] = True\n",
        "                neighbor_neighbors = self._get_neighbors(neighbor_idx, distance_matrix)\n",
        "\n",
        "                if len(neighbor_neighbors) >= self.min_pts:\n",
        "                    queue.extend(neighbor_neighbors)\n",
        "\n",
        "            if labels[neighbor_idx] == -1:\n",
        "                labels[neighbor_idx] = cluster_id\n",
        "\n",
        "    def fit(self, X):\n",
        "        n_points = len(X)\n",
        "        visited = np.zeros(n_points, dtype=bool)\n",
        "        cluster_id = 0\n",
        "        self.labels_ = np.full(n_points, -1)\n",
        "        self.core_samples_ = []\n",
        "\n",
        "        distance_matrix = self._calculate_distance_matrix(X)\n",
        "\n",
        "        for point_idx in range(n_points):\n",
        "            if visited[point_idx]:\n",
        "                continue\n",
        "\n",
        "            visited[point_idx] = True\n",
        "            neighbors = self._get_neighbors(point_idx, distance_matrix)\n",
        "\n",
        "            if len(neighbors) >= self.min_pts:\n",
        "                self.core_samples_.append(point_idx)\n",
        "                self._expand_cluster(point_idx, neighbors, cluster_id, distance_matrix, visited, self.labels_)\n",
        "                cluster_id += 1\n",
        "\n",
        "        self.core_samples_ = np.array(self.core_samples_)\n",
        "        self.n_clusters_ = cluster_id\n",
        "        return self\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        self.fit(X)\n",
        "        return self.labels_\n",
        "\n",
        "def generate_concentric_spheres(radii=[3, 15], n_samples_per_sphere=1000, noise=0.2, random_state=42):\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    X, y = [], []\n",
        "\n",
        "    for i, r in enumerate(radii):\n",
        "        phi = rng.uniform(0, 2*np.pi, n_samples_per_sphere)\n",
        "        costheta = rng.uniform(-1, 1, n_samples_per_sphere)\n",
        "        theta = np.arccos(costheta)\n",
        "        rr = r + noise * rng.standard_normal(n_samples_per_sphere)\n",
        "\n",
        "        x = rr * np.sin(theta) * np.cos(phi)\n",
        "        y_ = rr * np.sin(theta) * np.sin(phi)\n",
        "        z = rr * np.cos(theta)\n",
        "\n",
        "        X.append(np.vstack((x, y_, z)).T)\n",
        "        y.append(np.full(n_samples_per_sphere, i))\n",
        "\n",
        "    X = np.vstack(X)\n",
        "    y = np.concatenate(y)\n",
        "    return X, y\n",
        "\n",
        "def plot_k_distance(X, min_pts, title=\"K-Distance Plot\"):\n",
        "    k = int(min_pts - 1)\n",
        "\n",
        "    nn = NearestNeighbors(n_neighbors=k+1, metric=\"euclidean\")\n",
        "    nn.fit(X)\n",
        "    distances, _ = nn.kneighbors(X)\n",
        "\n",
        "    kth_distances = distances[:, k]\n",
        "    k_distances_sorted = np.sort(kth_distances)[::-1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(len(k_distances_sorted)), k_distances_sorted, linewidth=2, label=f'{k}-distance')\n",
        "    plt.xlabel(\"Pontos ordenados por distância\")\n",
        "    plt.ylabel(f\"Distância ao {k}-ésimo vizinho mais próximo\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.savefig('k_distance_spheres.png')\n",
        "    plt.show()\n",
        "\n",
        "X_spheres, y_spheres = generate_concentric_spheres(radii=[3, 8, 12], n_samples_per_sphere=200, noise=0.4)\n",
        "scaler = StandardScaler()\n",
        "X_spheres = scaler.fit_transform(X_spheres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvDJEI_yQXPH"
      },
      "outputs": [],
      "source": [
        "# K-Distance para min_pts = 10 (k=9) e 20 (k=19)\n",
        "# Um número razoável de min_pts para 600 amostras (200 por cluster) é 10 ou 20.\n",
        "plot_k_distance(X_spheres, min_pts=10, title=\"K-Distance Plot (min_pts=10) - Esferas\")\n",
        "plot_k_distance(X_spheres, min_pts=20, title=\"K-Distance Plot (min_pts=20) - Esferas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando o gráfico K-Distance para min_pts=10, o \"cotovelo\" da curva, onde a inclinação muda bruscamente, parece estar em torno de ε≈0.15. Para min_pts=20, o valor é ligeiramente maior, mas também próximo de ε≈0.15."
      ],
      "metadata": {
        "id": "sIlqMfJba3gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros escolhidos: min_pts=10; ε=0.15; best_eps = 0.15; best_min_pts = 10\n",
        "\n",
        "dbscan_spheres = DBSCAN(eps=best_eps, min_pts=best_min_pts)\n",
        "labels_spheres = dbscan_spheres.fit_predict(X_spheres)\n",
        "\n",
        "n_clusters_spheres = len(np.unique(labels_spheres)) - (1 if -1 in np.unique(labels_spheres) else 0)\n",
        "n_noise_spheres = np.sum(labels_spheres == -1)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "unique_labels = np.unique(labels_spheres)\n",
        "colors = plt.cm.get_cmap('viridis')(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "for k, label in enumerate(unique_labels):\n",
        "    mask = labels_spheres == label\n",
        "    if label == -1:\n",
        "        ax.scatter(X_spheres[mask, 0], X_spheres[mask, 1], X_spheres[mask, 2],\n",
        "                   c='black', marker='x', s=20, alpha=0.5, label='Ruído')\n",
        "    else:\n",
        "        ax.scatter(X_spheres[mask, 0], X_spheres[mask, 1], X_spheres[mask, 2],\n",
        "                   color=colors[k], s=40, alpha=0.8, label=f'Cluster {label}')\n",
        "\n",
        "ax.set_title(f'DBSCAN (eps={best_eps}, min_pts={best_min_pts}) - Esferas 3D')\n",
        "ax.set_xlabel('Feature 1 (Scaled)')\n",
        "ax.set_ylabel('Feature 2 (Scaled)')\n",
        "ax.set_zlabel('Feature 3 (Scaled)')\n",
        "ax.legend()\n",
        "plt.savefig('dbscan_spheres_3d.png')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Resultados DBSCAN com $\\\\varepsilon={best_eps}$ e $min\\_pts={best_min_pts}$:\")\n",
        "print(f\"Clusters encontrados: {n_clusters_spheres}\")\n",
        "print(f\"Pontos classificados como ruído: {n_noise_spheres}\")"
      ],
      "metadata": {
        "id": "ROHB5Xiya6TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O DBSCAN, utilizando a distância euclidiana padrão, não conseguiu separar as três esferas concêntricas. O resultado mostra apenas 1 cluster (ou no máximo 2, dependendo do min_pts). Isso ocorre porque a distância euclidiana, ao ser aplicada a pontos em esferas concêntricas, vê a região entre as esferas como uma ponte de baixa densidade, mas a vizinhança ε não é suficiente para ligar os pontos radialmente, mas sim tangencialmente. A distância euclidiana não é a métrica apropriada para este dataset, pois os clusters são definidos pela distância à origem (o raio), e não pela distância entre si no espaço 3D."
      ],
      "metadata": {
        "id": "oc8HLYjPa_M7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am5viQzkQXPH"
      },
      "source": [
        "### Exercício 2: DBSCAN com distância radial\n",
        "\n",
        "Usando os dados das **3 esferas concêntricas** do exercício anterior:\n",
        "\n",
        "1. Implemente a **distância radial** e use-a no DBSCAN. A **distância radial** entre dois pontos \\(x_i\\) e \\(x_j\\) é a diferença absoluta entre suas distâncias à origem: $d_{\\text{radial}}(x_i, x_j) = \\big|\\;\\|x_i\\|_2 - \\|x_j\\|_2\\;\\big|$\n",
        "2. Plote o **K-Distance radial** para sugerir `eps`.  \n",
        "3. Teste combinações de `eps` e `min_samples`.  \n",
        "4. Visualize em 3D os clusters obtidos e compare com o resultado usando distância euclidiana.  \n",
        "5. Comente brevemente qual configuração foi melhor e por quê a métrica radial ajuda nesse dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def radial_distance_metric(X_1, X_2):\n",
        "    \"\"\"\n",
        "    Calcula a distância radial | ||x_1||_2 - ||x_2||_2 |\n",
        "\n",
        "    X_1 e X_2 são arrays de pontos (N x D)\n",
        "    Retorna uma matriz de distâncias (N_1 x N_2)\n",
        "    \"\"\"\n",
        "    norms_1 = np.linalg.norm(X_1, axis=1)\n",
        "    norms_2 = np.linalg.norm(X_2, axis=1)\n",
        "\n",
        "    return np.abs(np.subtract.outer(norms_1, norms_2))\n",
        "\n",
        "class DBSCAN_Radial(DBSCAN):\n",
        "    def __init__(self, eps=0.5, min_pts=5, metric='euclidean'):\n",
        "        super().__init__(eps, min_pts, metric)\n",
        "\n",
        "    def _calculate_distance_matrix(self, X):\n",
        "        if self.metric == 'radial':\n",
        "            return radial_distance_metric(X, X)\n",
        "\n",
        "        return super()._calculate_distance_matrix(X)\n",
        "\n",
        "def plot_k_distance_radial(X, min_pts, title=\"K-Distance Plot (Métrica Radial)\"):\n",
        "    k = int(min_pts - 1)\n",
        "\n",
        "    D_radial = radial_distance_metric(X, X)\n",
        "\n",
        "    sorted_distances = np.sort(D_radial, axis=1)[:, 1:]\n",
        "\n",
        "    kth_distances = sorted_distances[:, k-1]\n",
        "    k_distances_sorted = np.sort(kth_distances)[::-1]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(len(k_distances_sorted)), k_distances_sorted, linewidth=2, label=f'{k}-distance (Radial)')\n",
        "    plt.xlabel(\"Pontos ordenados por distância\")\n",
        "    plt.ylabel(f\"Distância Radial ao {k}-ésimo vizinho mais próximo\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.savefig('k_distance_radial_spheres.png')\n",
        "    plt.show()\n",
        "\n",
        "plot_k_distance_radial(X_spheres, min_pts=10, title=\"K-Distance Radial (min_pts=10) - Esferas\")"
      ],
      "metadata": {
        "id": "T-SYNxXLbCEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O \"cotovelo\" no gráfico K-Distance com métrica radial é extremamente nítido e ocorre em um valor muito baixo, em torno de ε≈0.05."
      ],
      "metadata": {
        "id": "sit1UY7cbFmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros escolhidos (Radial): min_pts=10; ε=0.05\n",
        "\n",
        "best_eps_radial = 0.05\n",
        "best_min_pts_radial = 10\n",
        "\n",
        "dbscan_radial = DBSCAN_Radial(eps=best_eps_radial, min_pts=best_min_pts_radial, metric='radial')\n",
        "labels_radial = dbscan_radial.fit_predict(X_spheres)\n",
        "\n",
        "n_clusters_radial = len(np.unique(labels_radial)) - (1 if -1 in np.unique(labels_radial) else 0)\n",
        "n_noise_radial = np.sum(labels_radial == -1)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "unique_labels_radial = np.unique(labels_radial)\n",
        "colors_radial = plt.cm.get_cmap('viridis')(np.linspace(0, 1, len(unique_labels_radial)))\n",
        "\n",
        "for k, label in enumerate(unique_labels_radial):\n",
        "    mask = labels_radial == label\n",
        "    if label == -1:\n",
        "        ax.scatter(X_spheres[mask, 0], X_spheres[mask, 1], X_spheres[mask, 2],\n",
        "                   c='black', marker='x', s=20, alpha=0.5, label='Ruído')\n",
        "    else:\n",
        "        ax.scatter(X_spheres[mask, 0], X_spheres[mask, 1], X_spheres[mask, 2],\n",
        "                   color=colors_radial[k], s=40, alpha=0.8, label=f'Cluster {label}')\n",
        "\n",
        "ax.set_title(f'DBSCAN RADIAL (eps={best_eps_radial}, min_pts={best_min_pts_radial}) - Esferas 3D')\n",
        "ax.set_xlabel('Feature 1 (Scaled)')\n",
        "ax.set_ylabel('Feature 2 (Scaled)')\n",
        "ax.set_zlabel('Feature 3 (Scaled)')\n",
        "ax.legend()\n",
        "plt.savefig('dbscan_radial_spheres_3d.png')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Resultados DBSCAN RADIAL com $\\\\varepsilon={best_eps_radial}$ e $min\\_pts={best_min_pts_radial}$:\")\n",
        "print(f\"Clusters encontrados: {n_clusters_radial}\")\n",
        "print(f\"Pontos classificados como ruído: {n_noise_radial}\")"
      ],
      "metadata": {
        "id": "DsBbiXKlbH_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A configuração do DBSCAN com Métrica Radial (K=3, ε=0.05, min_pts=10) foi melhor do que a Eucliana (K=1).\n",
        "\n",
        "A métrica radial d\n",
        "radial\n",
        "​\n",
        " (x\n",
        "i\n",
        "​\n",
        " ,x\n",
        "j\n",
        "​\n",
        " )=\n",
        "\n",
        "​\n",
        " ∥x\n",
        "i\n",
        "​\n",
        " ∥\n",
        "2\n",
        "​\n",
        " −∥x\n",
        "j\n",
        "​\n",
        " ∥\n",
        "2\n",
        "​\n",
        "  \n",
        "\n",
        "​\n",
        "  funcionou perfeitamente para este dataset porque:\n",
        "\n",
        "Natureza dos Dados: As três esferas concêntricas são definidas unicamente por seu raio (distância à origem).\n",
        "\n",
        "Filtro Eficaz: A métrica radial isola essa característica (o raio) e ignora a posição angular, que é irrelevante para a clusterização. Pontos pertencentes à mesma casca esférica (raio similar) terão uma distância radial próxima de zero, formando clusters densos, enquanto pontos em cascas diferentes terão uma distância radial grande, prevenindo a ligação.\n",
        "\n",
        "DBSCAN Ideal: Como o DBSCAN busca regiões densas, a métrica radial permitiu que ele identificasse a densidade ao longo da dimensão do raio, resultando na separação correta em três clusters distintos."
      ],
      "metadata": {
        "id": "iGKA1fGkbQKa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJKElAUpQXPH"
      },
      "source": [
        "### Exercício 3: Detecção de Anomalias com DBSCAN e DTW\n",
        "\n",
        "O **DTW (Dynamic Time Warping)** mede a similaridade entre séries temporais mesmo quando estão defasadas ou com velocidades diferentes, alinhando-as de forma elástica. Isso permite detectar padrões semelhantes sem que a defasagem atrapalhe.\n",
        "\n",
        "Pode ser calculado por:\n",
        "```python\n",
        "from dtaidistance import dtw\n",
        "\n",
        "n = len(X)              # número de séries\n",
        "D = np.zeros((n, n))    # matriz de distâncias\n",
        "\n",
        "for i in range(n):\n",
        "    for j in range(i+1, n):\n",
        "        dist = dtw.distance_fast(X[i], X[j])  # distância DTW\n",
        "        D[i, j] = D[j, i] = dist              # matriz simétrica\n",
        "````\n",
        "\n",
        "**Tarefas:**\n",
        "1. Use o dataset de senóides com variação e **anomalias simuladas**.  \n",
        "2. Adicione a métrica DTW no DBSCAN.\n",
        "3. Experimente diferentes valores de `eps` e `min_samples` até que o modelo consiga separar bem séries normais das anômalas.  \n",
        "4. Plote todas as séries, usando uma cor para as normais e outra para as anomalias detectadas (`label = -1`).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpM6uJ65QXPH"
      },
      "outputs": [],
      "source": [
        "from dtaidistance import dtw\n",
        "\n",
        "def generate_time_series_dataset(n_series=50, length=100, noise=0.1, n_outliers=2, random_state=42):\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    X, y = [], []\n",
        "    t = np.linspace(0, 4*np.pi, length)\n",
        "\n",
        "    for _ in range(n_series):\n",
        "        amp = rng.uniform(0.8, 1.2)\n",
        "        freq = rng.uniform(0.9, 1.1)\n",
        "        phase = rng.uniform(0, 0.5*np.pi)\n",
        "        series = amp * np.sin(freq * t + phase) + noise * rng.normal(size=length)\n",
        "        X.append(series)\n",
        "        y.append(0)  # normal\n",
        "\n",
        "    for _ in range(n_outliers):\n",
        "        amp = rng.uniform(1.5, 2.0)\n",
        "        freq = rng.uniform(1.2, 1.5)\n",
        "        series = amp * np.sin(freq * t) + noise * rng.normal(size=length)\n",
        "        if rng.random() < 0.5:\n",
        "            series[length//2] += 3  # pico\n",
        "        else:\n",
        "            series += rng.normal(2.0, 0.5)  # deslocamento\n",
        "        X.append(series)\n",
        "        y.append(-1)  # anomalia\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_series, y_series = generate_time_series_dataset(n_series=50, n_outliers=5, random_state=42) # Aumentando outliers para 5\n",
        "n_series = len(X_series)\n",
        "D_dtw = np.zeros((n_series, n_series))\n",
        "\n",
        "print(f\"Calculando matriz de distâncias DTW ({n_series} x {n_series})...\")\n",
        "\n",
        "for i in range(n_series):\n",
        "    for j in range(i+1, n_series):\n",
        "        dist = dtw.distance_fast(X_series[i], X_series[j])\n",
        "        D_dtw[i, j] = D_dtw[j, i] = dist\n",
        "\n",
        "def plot_k_distance_precomputed(D, min_pts, title=\"K-Distance Plot (Precomputed DTW)\"):\n",
        "    k = int(min_pts - 1)\n",
        "\n",
        "    sorted_distances = np.sort(D, axis=1)[:, 1:]\n",
        "\n",
        "    kth_distances = sorted_distances[:, k-1]\n",
        "    k_distances_sorted = np.sort(kth_distances)[::-1]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(len(k_distances_sorted)), k_distances_sorted, linewidth=2, label=f'{k}-distance (DTW)')\n",
        "    plt.xlabel(\"Séries ordenadas por distância\")\n",
        "    plt.ylabel(f\"DTW Distância ao {k}-ésimo vizinho mais próximo\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.savefig('k_distance_dtw.png')\n",
        "    plt.show()\n",
        "\n",
        "# Usar min_pts = 10\n",
        "plot_k_distance_precomputed(D_dtw, min_pts=10, title=\"K-Distance DTW (min_pts=10)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O \"cotovelo\" no gráfico K-Distance para DTW parece ocorrer em torno de ε≈1.5."
      ],
      "metadata": {
        "id": "P6fBIvQjbWa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros escolhidos (DTW): min_pts=10 (valor razoável para 55 séries); ε=1.5.\n",
        "\n",
        "best_eps_dtw = 1.5\n",
        "best_min_pts_dtw = 10\n",
        "\n",
        "dbscan_dtw = DBSCAN(eps=best_eps_dtw, min_pts=best_min_pts_dtw, metric='precomputed')\n",
        "labels_dtw = dbscan_dtw.fit_predict(D_dtw)\n",
        "\n",
        "n_clusters_dtw = len(np.unique(labels_dtw)) - (1 if -1 in np.unique(labels_dtw) else 0)\n",
        "n_noise_dtw = np.sum(labels_dtw == -1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, series in enumerate(X_series):\n",
        "    label = labels_dtw[i]\n",
        "    if label == -1:\n",
        "        plt.plot(series, color='red', alpha=0.9, linewidth=1.5, label='Anomalia Detectada' if i == np.where(labels_dtw == -1)[0][0] else \"\")\n",
        "    else:\n",
        "        plt.plot(series, color='blue', alpha=0.5, label='Série Normal' if i == np.where(labels_dtw != -1)[0][0] else \"\")\n",
        "\n",
        "plt.title(f'DBSCAN com DTW (eps={best_eps_dtw}, min_pts={best_min_pts_dtw}) - Detecção de Anomalias')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Valor da Série')\n",
        "plt.legend()\n",
        "plt.savefig('dbscan_dtw_anomalies.png')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Resultados DBSCAN com DTW:\")\n",
        "print(f\"Clusters encontrados (séries normais): {n_clusters_dtw}\")\n",
        "print(f\"Séries classificadas como ruído (anomalias): {n_noise_dtw}\")"
      ],
      "metadata": {
        "id": "NS7WC6YpbXWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}